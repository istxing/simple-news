# coding=utf-8
"""
å­˜å‚¨æ¨¡å—
è´Ÿè´£å°†æ–°é—»æ•°æ®ä¿å­˜åˆ° SQLite æ•°æ®åº“
"""

import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import pytz
from simple_news.topic_classifier import classify_title


class NewsStorage:
    """æ–°é—»å­˜å‚¨ç±»"""

    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–å­˜å‚¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        storage_config = config['storage']
        
        # æ•°æ®ç›®å½•
        self.data_dir = Path(storage_config['data_dir'])
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ—¶åŒº
        self.timezone = pytz.timezone(config['app']['timezone'])
        
        # ä¿ç•™å¤©æ•°
        self.retention_days = storage_config.get('retention_days', 30)
        
        # è¿ç§»æ—§æ•°æ®åº“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._migrate_from_single_db()
    
    def _get_db_path(self, date: Optional[str] = None) -> Path:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®åº“è·¯å¾„
        
        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
        Returns:
            æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        if date is None:
            date = datetime.now(self.timezone).strftime('%Y-%m-%d')
        
        # æ ¼å¼åŒ–ä¸º YYYYMMDD
        date_str = date.replace('-', '')
        db_filename = f'news_{date_str}.db'
        
        return self.data_dir / db_filename



    def _init_database_for_path(self, db_path: Path):
        """
        ä¸ºæŒ‡å®šè·¯å¾„åˆå§‹åŒ–æ•°æ®åº“è¡¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # æ–°é—»è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    platform_id TEXT NOT NULL,
                    platform_name TEXT NOT NULL,
                    title TEXT NOT NULL,
                    url TEXT,
                    mobile_url TEXT,
                    rank INTEGER,
                    crawl_time TEXT NOT NULL,
                    topic TEXT DEFAULT 'other',
                    topic_score REAL DEFAULT 0,
                    topic_reason TEXT DEFAULT '',
                    date TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')

            # å…¼å®¹å·²æœ‰æ•°æ®åº“ï¼šä¸ºæ—§è¡¨è¡¥é½ä¸»é¢˜å­—æ®µ
            existing_cols = {row[1] for row in cursor.execute("PRAGMA table_info(news)").fetchall()}
            if 'topic' not in existing_cols:
                cursor.execute("ALTER TABLE news ADD COLUMN topic TEXT DEFAULT 'other'")
            if 'topic_score' not in existing_cols:
                cursor.execute("ALTER TABLE news ADD COLUMN topic_score REAL DEFAULT 0")
            if 'topic_reason' not in existing_cols:
                cursor.execute("ALTER TABLE news ADD COLUMN topic_reason TEXT DEFAULT ''")
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_news_date 
                ON news(date)
            ''')
            
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_news_platform 
                ON news(platform_id, date)
            ''')

            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_news_topic
                ON news(topic, date)
            ''')

            # å…¼å®¹å†å²é»˜è®¤å€¼
            cursor.execute("UPDATE news SET topic='other' WHERE topic='general'")

            # å¯¹æ—§æ•°æ®åšä¸€æ¬¡ä¸»é¢˜å›å¡«ï¼Œç¡®ä¿å†å²æ•°æ®ä¹Ÿå¯æŒ‰ä¸»é¢˜ç­›é€‰
            self._backfill_topics(conn)
            
            # å…³é”®è¯ç»Ÿè®¡è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS keyword_stats (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    keyword TEXT NOT NULL,
                    count INTEGER NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')
            
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_keyword_date 
                ON keyword_stats(date)
            ''')
            
            # æ¨é€è®°å½•è¡¨ (ç”¨äºå»é‡)
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS pushed_news (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')
            
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_pushed_title 
                ON pushed_news(title, date)
            ''')
            
            conn.commit()

    def _backfill_topics(self, conn: sqlite3.Connection):
        """ä¸ºå†å²æœªåˆ†ç±»æ–°é—»è¡¥é½ topic/topic_score/topic_reasonã€‚"""
        cursor = conn.cursor()
        rows = cursor.execute(
            '''
            SELECT id, title
            FROM news
            WHERE
                topic IS NULL OR topic = '' OR
                topic_score IS NULL OR topic_score = 0 OR
                topic_reason IS NULL OR topic_reason = ''
            '''
        ).fetchall()
        if not rows:
            return

        topics_conf = self.config.get('topics', {})
        updates = []
        for row_id, title in rows:
            topic, topic_score, topic_reason = classify_title(
                title,
                topics_conf,
                default_topic='other',
            )
            updates.append((topic, topic_score, topic_reason, row_id))

        cursor.executemany(
            '''
            UPDATE news
            SET topic = ?, topic_score = ?, topic_reason = ?
            WHERE id = ?
            ''',
            updates,
        )

    def is_pushed(self, title: str) -> bool:
        """
        æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å·²åœ¨ä»Šå¤©æ¨é€è¿‡
        
        Args:
            title: æ–°é—»æ ‡é¢˜
            
        Returns:
            æ˜¯å¦å·²æ¨é€
        """
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        db_path = self._get_db_path(today)
        
        if not db_path.exists():
            return False
            
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT 1 FROM pushed_news WHERE title = ? AND date = ?", 
                (title, today)
            )
            return cursor.fetchone() is not None

    def mark_pushed(self, titles: List[str]):
        """
        æ ‡è®°æ ‡é¢˜ä¸ºå·²æ¨é€
        
        Args:
            titles: æ ‡é¢˜åˆ—è¡¨
        """
        if not titles:
            return
            
        now = datetime.now(self.timezone)
        created_at = now.strftime('%Y-%m-%d %H:%M:%S')
        today = now.strftime('%Y-%m-%d')
        db_path = self._get_db_path(today)
        
        # ç¡®ä¿è¡¨å­˜åœ¨
        self._init_database_for_path(db_path)
            
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            data = [(title, today, created_at) for title in titles]
            cursor.executemany(
                "INSERT INTO pushed_news (title, date, created_at) VALUES (?, ?, ?)",
                data
            )
            conn.commit()
            
    def filter_pushed_news(self, news_list: List[Dict]) -> List[Dict]:
        """
        è¿‡æ»¤æ‰å·²æ¨é€çš„æ–°é—»
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            æœªæ¨é€çš„æ–°é—»åˆ—è¡¨
        """
        if not news_list:
            return []
            
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        db_path = self._get_db_path(today)
        
        if not db_path.exists():
            return news_list
            
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            # è·å–ä»Šå¤©æ‰€æœ‰å·²æ¨é€çš„æ ‡é¢˜
            cursor.execute("SELECT title FROM pushed_news WHERE date = ?", (today,))
            pushed_titles = {row[0] for row in cursor.fetchall()}
            
        return [news for news in news_list if news['title'] not in pushed_titles]

    
    def _migrate_from_single_db(self):
        """
        ä»å•ä¸€æ•°æ®åº“è¿ç§»åˆ°æŒ‰æ—¥æœŸåˆ†åº“
        å°† news.db ä¸­çš„æ•°æ®æŒ‰æ—¥æœŸæ‹†åˆ†åˆ°ç‹¬ç«‹æ•°æ®åº“
        """
        old_db = self.data_dir / 'news.db'
        
        if not old_db.exists():
            return
        
        print("ğŸ”„ æ£€æµ‹åˆ°æ—§æ•°æ®åº“ï¼Œå¼€å§‹è¿ç§»...")
        
        try:
            # è¯»å–æ‰€æœ‰æ•°æ®
            with sqlite3.connect(old_db) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM news")
                rows = cursor.fetchall()
                columns = [d[0] for d in cursor.description] if cursor.description else []
            
            if not rows:
                print("  æ—§æ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡è¿ç§»")
                return
            
            # æŒ‰æ—¥æœŸåˆ†ç»„
            from collections import defaultdict
            by_date = defaultdict(list)
            
            col_idx = {name: i for i, name in enumerate(columns)}
            required = [
                'id', 'platform_id', 'platform_name', 'title', 'url', 'mobile_url',
                'rank', 'crawl_time', 'date', 'created_at'
            ]
            for row in rows:
                # å…¼å®¹æ—§/æ–°ç»“æ„ï¼šæŒ‰åˆ—åæ˜ å°„ï¼Œä¸ä¾èµ–å›ºå®šç´¢å¼•
                mapped = []
                for col in required:
                    idx = col_idx.get(col)
                    mapped.append(row[idx] if idx is not None else None)
                date = mapped[8]
                if not date:
                    continue
                by_date[date].append(tuple(mapped))
            
            # å†™å…¥å„æ—¥æœŸæ•°æ®åº“
            migrated_count = 0
            for date, news_list in by_date.items():
                db_path = self._get_db_path(date)
                self._init_database_for_path(db_path)
                
                with sqlite3.connect(db_path) as conn:
                    conn.executemany(
                        '''INSERT INTO news (
                            id, platform_id, platform_name, title, url, mobile_url,
                            rank, crawl_time, date, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                        news_list
                    )
                    migrated_count += len(news_list)
                
                print(f"  âœ“ {date}: {len(news_list)} æ¡æ–°é—»")
            
            # å¤‡ä»½å¹¶åˆ é™¤æ—§æ•°æ®åº“
            backup_path = self.data_dir / 'news.db.backup'
            old_db.rename(backup_path)
            print(f"âœ“ è¿ç§»å®Œæˆï¼å…±è¿ç§» {migrated_count} æ¡æ–°é—»")
            print(f"  æ—§æ•°æ®åº“å·²å¤‡ä»½ä¸º: {backup_path.name}")
            
        except Exception as e:
            print(f"âœ— è¿ç§»å¤±è´¥: {str(e)}")
            print("  å°†ç»§ç»­ä½¿ç”¨æ—§æ•°æ®åº“æ ¼å¼")

    def save_news(self, platform_data_list: List[Dict]) -> int:
        """
        ä¿å­˜æ–°é—»æ•°æ®
        
        Args:
            platform_data_list: å¹³å°æ•°æ®åˆ—è¡¨
            
        Returns:
            ä¿å­˜çš„æ–°é—»æ¡æ•°
        """
        now = datetime.now(self.timezone)
        crawl_time = now.strftime('%Y-%m-%d %H:%M:%S')
        date = now.strftime('%Y-%m-%d')
        
        # è·å–å½“å¤©æ•°æ®åº“è·¯å¾„
        db_path = self._get_db_path(date)
        
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self._init_database_for_path(db_path)
        
        total_saved = 0
        total_skipped = 0
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()

            # é¢„åŠ è½½å½“æ—¥å·²å­˜åœ¨çš„ (platform_id, title)ï¼Œé¿å…é‡å¤å…¥åº“
            cursor.execute('''
                SELECT platform_id, title FROM news WHERE date = ?
            ''', (date,))
            existing_keys = {(row[0], row[1]) for row in cursor.fetchall()}
            batch_keys = set()
            
            for platform_data in platform_data_list:
                platform_id = platform_data['platform_id']
                platform_name = platform_data['platform_name']
                
                for news_item in platform_data['news_list']:
                    dedup_key = (platform_id, news_item['title'])
                    if dedup_key in existing_keys or dedup_key in batch_keys:
                        total_skipped += 1
                        continue

                    topic, topic_score, topic_reason = classify_title(
                        news_item['title'],
                        self.config.get('topics', {}),
                        default_topic='other'
                    )

                    cursor.execute('''
                        INSERT INTO news (
                            platform_id, platform_name, title, url, mobile_url,
                            rank, crawl_time, topic, topic_score, topic_reason, date, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        platform_id,
                        platform_name,
                        news_item['title'],
                        news_item['url'],
                        news_item['mobile_url'],
                        news_item['rank'],
                        crawl_time,
                        topic,
                        topic_score,
                        topic_reason,
                        date,
                        crawl_time,
                    ))
                    batch_keys.add(dedup_key)
                    total_saved += 1
            
            conn.commit()
        
        print(f"âœ“ å·²ä¿å­˜ {total_saved} æ¡æ–°é—»åˆ°æ•°æ®åº“ï¼ˆè·³è¿‡é‡å¤ {total_skipped} æ¡ï¼‰")
        
        # æ¸…ç†æ—§æ•°æ®
        if self.retention_days > 0:
            self._cleanup_old_data()
        
        return total_saved

    def save_keyword_stats(self, keyword_stats: Dict[str, int]):
        """
        ä¿å­˜å…³é”®è¯ç»Ÿè®¡
        
        Args:
            keyword_stats: {å…³é”®è¯: å‡ºç°æ¬¡æ•°} å­—å…¸
        """
        if not keyword_stats:
            return
        
        now = datetime.now(self.timezone)
        created_at = now.strftime('%Y-%m-%d %H:%M:%S')
        date = now.strftime('%Y-%m-%d')
        
        # è·å–å½“å¤©æ•°æ®åº“è·¯å¾„
        db_path = self._get_db_path(date)
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            for keyword, count in keyword_stats.items():
                cursor.execute('''
                    INSERT INTO keyword_stats (keyword, count, date, created_at)
                    VALUES (?, ?, ?, ?)
                ''', (keyword, count, date, created_at))
            
            conn.commit()

    def get_today_news(self, mode: str = 'daily') -> List[Dict]:
        """
        è·å–ä»Šå¤©çš„æ–°é—»
        
        Args:
            mode: æŸ¥è¯¢æ¨¡å¼
                - daily: å…¨å¤©æ±‡æ€»ï¼ˆä»Šå¤©æ‰€æœ‰çˆ¬å–çš„æ–°é—»ï¼‰
                - current: å½“å‰æ¦œå•ï¼ˆæœ€æ–°ä¸€æ¬¡çˆ¬å–çš„æ–°é—»ï¼‰
                - incremental: å¢é‡æ›´æ–°ï¼ˆè¿‡æ»¤ä»Šå¤©+æ˜¨å¤©å·²æœ‰çš„ï¼Œè¿”å›çœŸæ­£æ–°å¢çš„æ–°é—»ï¼‰
        
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        db_path = self._get_db_path(today)
        
        # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not db_path.exists():
            return []
        
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            if mode == 'current':
                # è·å–æœ€æ–°ä¸€æ‰¹çˆ¬å–çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ? 
                    AND crawl_time = (
                        SELECT MAX(crawl_time) FROM news WHERE date = ?
                    )
                    ORDER BY platform_id, rank
                ''', (today, today))
            elif mode == 'incremental':
                # å¢é‡æ¨¡å¼ï¼šå¯¹æ¯”ä»Šå¤©å·²ä¿å­˜çš„æ‰€æœ‰æ–°é—»ï¼ˆæœ€æ–°ä¸€æ‰¹ä¹‹å‰çš„ï¼‰ï¼Œè¿”å›æ–°å¢çš„æ–°é—»
                # è·å–æœ€æ–°ä¸€æ‰¹çš„çˆ¬å–æ—¶é—´
                cursor.execute('''
                    SELECT MAX(crawl_time) as latest_time FROM news WHERE date = ?
                ''', (today,))
                result = cursor.fetchone()
                latest_time = result['latest_time'] if result else None
                
                if not latest_time:
                    return []
                
                # è·å–ä»Šå¤©è¿™æ‰¹ä¹‹å‰çš„æ‰€æœ‰æ ‡é¢˜ï¼ˆä¸åŒ…æ‹¬æœ€æ–°ä¸€æ‰¹ï¼‰
                cursor.execute('''
                    SELECT DISTINCT title FROM news 
                    WHERE date = ? AND crawl_time < ?
                ''', (today, latest_time))
                existing_titles = {row['title'] for row in cursor.fetchall()}
                
                # ä¹Ÿæ£€æŸ¥æ˜¨å¤©çš„æ•°æ®åº“
                yesterday = (datetime.now(self.timezone) - timedelta(days=1)).strftime('%Y-%m-%d')
                yesterday_db = self._get_db_path(yesterday)
                if yesterday_db.exists():
                    with sqlite3.connect(yesterday_db) as yesterday_conn:
                        yesterday_conn.row_factory = sqlite3.Row
                        yesterday_cursor = yesterday_conn.cursor()
                        yesterday_cursor.execute('SELECT DISTINCT title FROM news')
                        existing_titles.update({row['title'] for row in yesterday_cursor.fetchall()})
                
                # è·å–æœ€æ–°ä¸€æ‰¹çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ? AND crawl_time = ?
                    ORDER BY platform_id, rank
                ''', (today, latest_time))
                latest_news = [dict(row) for row in cursor.fetchall()]
                
                # è¿‡æ»¤å‡ºæ–°å¢çš„æ–°é—»ï¼ˆæ ‡é¢˜ä¸åœ¨ä¹‹å‰çš„è®°å½•ä¸­ï¼‰
                incremental_news = [
                    news for news in latest_news 
                    if news['title'] not in existing_titles
                ]
                return incremental_news
            else:  # daily
                # è·å–å…¨å¤©çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ?
                    ORDER BY created_at DESC, platform_id, rank
                ''', (today,))
            
            rows = cursor.fetchall()
            return [dict(row) for row in rows]

    def _cleanup_old_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆåˆ é™¤æ—§çš„æ•°æ®åº“æ–‡ä»¶ï¼‰"""
        if self.retention_days <= 0:
            return
        
        cutoff_date = datetime.now(self.timezone) - timedelta(days=self.retention_days)
        
        # éå†æ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
        deleted_count = 0
        for db_file in self.data_dir.glob('news_*.db'):
            # æå–æ—¥æœŸ
            date_str = db_file.stem.replace('news_', '')  # 20260206
            try:
                file_date = datetime.strptime(date_str, '%Y%m%d')
                
                # å¦‚æœæ–‡ä»¶è¿‡æœŸï¼Œåˆ é™¤
                if file_date.date() < cutoff_date.date():
                    db_file.unlink()
                    deleted_count += 1
                    print(f"  âœ“ å·²åˆ é™¤è¿‡æœŸæ•°æ®åº“: {db_file.name}")
            except ValueError:
                # è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„æ–‡ä»¶
                continue
        
        if deleted_count > 0:
            print(f"âœ“ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¿‡æœŸæ•°æ®åº“æ–‡ä»¶")

    def get_database_stats(self) -> Dict:
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_news = 0
        platforms = set()
        db_files = list(self.data_dir.glob('news_*.db'))
        
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        today_news = 0
        
        # éå†æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
        for db_file in db_files:
            with sqlite3.connect(db_file) as conn:
                cursor = conn.cursor()
                
                # ç»Ÿè®¡æ–°é—»æ•°
                cursor.execute("SELECT COUNT(*) FROM news")
                count = cursor.fetchone()[0]
                total_news += count
                
                # ç»Ÿè®¡ä»Šæ—¥æ–°é—»æ•°
                cursor.execute("SELECT COUNT(*) FROM news WHERE date = ?", (today,))
                today_count = cursor.fetchone()[0]
                today_news += today_count
                
                # ç»Ÿè®¡å¹³å°æ•°
                cursor.execute("SELECT DISTINCT platform_id FROM news")
                platforms.update([row[0] for row in cursor.fetchall()])
        
        # è®¡ç®—æ€»å¤§å°
        total_size = sum(f.stat().st_size for f in db_files) / (1024 * 1024)  # MB
        
        return {
            'total_news': total_news,
            'today_news': today_news,
            'platform_count': len(platforms),
            'database_count': len(db_files),
            'db_size_mb': round(total_size, 2),
            'data_dir': str(self.data_dir),
        }
