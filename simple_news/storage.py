# coding=utf-8
"""
å­˜å‚¨æ¨¡å—
è´Ÿè´£å°†æ–°é—»æ•°æ®ä¿å­˜åˆ° SQLite æ•°æ®åº“
"""

import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import pytz


class NewsStorage:
    """æ–°é—»å­˜å‚¨ç±»"""

    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–å­˜å‚¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        storage_config = config['storage']
        
        # æ•°æ®ç›®å½•
        self.data_dir = Path(storage_config['data_dir'])
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ—¶åŒº
        self.timezone = pytz.timezone(config['app']['timezone'])
        
        # ä¿ç•™å¤©æ•°
        self.retention_days = storage_config.get('retention_days', 30)
        
        # è¿ç§»æ—§æ•°æ®åº“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._migrate_from_single_db()
    
    def _get_db_path(self, date: Optional[str] = None) -> Path:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®åº“è·¯å¾„
        
        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
        Returns:
            æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        if date is None:
            date = datetime.now(self.timezone).strftime('%Y-%m-%d')
        
        # æ ¼å¼åŒ–ä¸º YYYYMMDD
        date_str = date.replace('-', '')
        db_filename = f'news_{date_str}.db'
        
        return self.data_dir / db_filename

    def _init_database_for_path(self, db_path: Path):
        """
        ä¸ºæŒ‡å®šè·¯å¾„åˆå§‹åŒ–æ•°æ®åº“è¡¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # æ–°é—»è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    platform_id TEXT NOT NULL,
                    platform_name TEXT NOT NULL,
                    title TEXT NOT NULL,
                    url TEXT,
                    mobile_url TEXT,
                    rank INTEGER,
                    crawl_time TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_news_date 
                ON news(date)
            ''')
            
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_news_platform 
                ON news(platform_id, date)
            ''')
            
            # å…³é”®è¯ç»Ÿè®¡è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS keyword_stats (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    keyword TEXT NOT NULL,
                    count INTEGER NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            ''')
            
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_keyword_date 
                ON keyword_stats(date)
            ''')
            
            conn.commit()
    
    def _migrate_from_single_db(self):
        """
        ä»å•ä¸€æ•°æ®åº“è¿ç§»åˆ°æŒ‰æ—¥æœŸåˆ†åº“
        å°† news.db ä¸­çš„æ•°æ®æŒ‰æ—¥æœŸæ‹†åˆ†åˆ°ç‹¬ç«‹æ•°æ®åº“
        """
        old_db = self.data_dir / 'news.db'
        
        if not old_db.exists():
            return
        
        print("ğŸ”„ æ£€æµ‹åˆ°æ—§æ•°æ®åº“ï¼Œå¼€å§‹è¿ç§»...")
        
        try:
            # è¯»å–æ‰€æœ‰æ•°æ®
            with sqlite3.connect(old_db) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM news")
                rows = cursor.fetchall()
            
            if not rows:
                print("  æ—§æ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡è¿ç§»")
                return
            
            # æŒ‰æ—¥æœŸåˆ†ç»„
            from collections import defaultdict
            by_date = defaultdict(list)
            
            for row in rows:
                date = row[8]  # date å­—æ®µç´¢å¼•
                by_date[date].append(row)
            
            # å†™å…¥å„æ—¥æœŸæ•°æ®åº“
            migrated_count = 0
            for date, news_list in by_date.items():
                db_path = self._get_db_path(date)
                self._init_database_for_path(db_path)
                
                with sqlite3.connect(db_path) as conn:
                    conn.executemany(
                        '''INSERT INTO news (
                            id, platform_id, platform_name, title, url, mobile_url,
                            rank, crawl_time, date, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                        news_list
                    )
                    migrated_count += len(news_list)
                
                print(f"  âœ“ {date}: {len(news_list)} æ¡æ–°é—»")
            
            # å¤‡ä»½å¹¶åˆ é™¤æ—§æ•°æ®åº“
            backup_path = self.data_dir / 'news.db.backup'
            old_db.rename(backup_path)
            print(f"âœ“ è¿ç§»å®Œæˆï¼å…±è¿ç§» {migrated_count} æ¡æ–°é—»")
            print(f"  æ—§æ•°æ®åº“å·²å¤‡ä»½ä¸º: {backup_path.name}")
            
        except Exception as e:
            print(f"âœ— è¿ç§»å¤±è´¥: {str(e)}")
            print("  å°†ç»§ç»­ä½¿ç”¨æ—§æ•°æ®åº“æ ¼å¼")

    def save_news(self, platform_data_list: List[Dict]) -> int:
        """
        ä¿å­˜æ–°é—»æ•°æ®
        
        Args:
            platform_data_list: å¹³å°æ•°æ®åˆ—è¡¨
            
        Returns:
            ä¿å­˜çš„æ–°é—»æ¡æ•°
        """
        now = datetime.now(self.timezone)
        crawl_time = now.strftime('%Y-%m-%d %H:%M:%S')
        date = now.strftime('%Y-%m-%d')
        
        # è·å–å½“å¤©æ•°æ®åº“è·¯å¾„
        db_path = self._get_db_path(date)
        
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self._init_database_for_path(db_path)
        
        total_saved = 0
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            for platform_data in platform_data_list:
                platform_id = platform_data['platform_id']
                platform_name = platform_data['platform_name']
                
                for news_item in platform_data['news_list']:
                    cursor.execute('''
                        INSERT INTO news (
                            platform_id, platform_name, title, url, mobile_url,
                            rank, crawl_time, date, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        platform_id,
                        platform_name,
                        news_item['title'],
                        news_item['url'],
                        news_item['mobile_url'],
                        news_item['rank'],
                        crawl_time,
                        date,
                        crawl_time,
                    ))
                    total_saved += 1
            
            conn.commit()
        
        print(f"âœ“ å·²ä¿å­˜ {total_saved} æ¡æ–°é—»åˆ°æ•°æ®åº“")
        
        # æ¸…ç†æ—§æ•°æ®
        if self.retention_days > 0:
            self._cleanup_old_data()
        
        return total_saved

    def save_keyword_stats(self, keyword_stats: Dict[str, int]):
        """
        ä¿å­˜å…³é”®è¯ç»Ÿè®¡
        
        Args:
            keyword_stats: {å…³é”®è¯: å‡ºç°æ¬¡æ•°} å­—å…¸
        """
        if not keyword_stats:
            return
        
        now = datetime.now(self.timezone)
        created_at = now.strftime('%Y-%m-%d %H:%M:%S')
        date = now.strftime('%Y-%m-%d')
        
        # è·å–å½“å¤©æ•°æ®åº“è·¯å¾„
        db_path = self._get_db_path(date)
        
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            for keyword, count in keyword_stats.items():
                cursor.execute('''
                    INSERT INTO keyword_stats (keyword, count, date, created_at)
                    VALUES (?, ?, ?, ?)
                ''', (keyword, count, date, created_at))
            
            conn.commit()

    def get_today_news(self, mode: str = 'daily') -> List[Dict]:
        """
        è·å–ä»Šå¤©çš„æ–°é—»
        
        Args:
            mode: æŸ¥è¯¢æ¨¡å¼
                - daily: å…¨å¤©æ±‡æ€»ï¼ˆä»Šå¤©æ‰€æœ‰çˆ¬å–çš„æ–°é—»ï¼‰
                - current: å½“å‰æ¦œå•ï¼ˆæœ€æ–°ä¸€æ¬¡çˆ¬å–çš„æ–°é—»ï¼‰
                - incremental: å¢é‡æ›´æ–°ï¼ˆè¿‡æ»¤ä»Šå¤©+æ˜¨å¤©å·²æœ‰çš„ï¼Œè¿”å›çœŸæ­£æ–°å¢çš„æ–°é—»ï¼‰
        
        Returns:
            æ–°é—»åˆ—è¡¨
        """
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        db_path = self._get_db_path(today)
        
        # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not db_path.exists():
            return []
        
        with sqlite3.connect(db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            if mode == 'current':
                # è·å–æœ€æ–°ä¸€æ‰¹çˆ¬å–çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ? 
                    AND crawl_time = (
                        SELECT MAX(crawl_time) FROM news WHERE date = ?
                    )
                    ORDER BY platform_id, rank
                ''', (today, today))
            elif mode == 'incremental':
                # å¢é‡æ¨¡å¼ï¼šå¯¹æ¯”ä»Šå¤©å·²ä¿å­˜çš„æ‰€æœ‰æ–°é—»ï¼ˆæœ€æ–°ä¸€æ‰¹ä¹‹å‰çš„ï¼‰ï¼Œè¿”å›æ–°å¢çš„æ–°é—»
                # è·å–æœ€æ–°ä¸€æ‰¹çš„çˆ¬å–æ—¶é—´
                cursor.execute('''
                    SELECT MAX(crawl_time) as latest_time FROM news WHERE date = ?
                ''', (today,))
                result = cursor.fetchone()
                latest_time = result['latest_time'] if result else None
                
                if not latest_time:
                    return []
                
                # è·å–ä»Šå¤©è¿™æ‰¹ä¹‹å‰çš„æ‰€æœ‰æ ‡é¢˜ï¼ˆä¸åŒ…æ‹¬æœ€æ–°ä¸€æ‰¹ï¼‰
                cursor.execute('''
                    SELECT DISTINCT title FROM news 
                    WHERE date = ? AND crawl_time < ?
                ''', (today, latest_time))
                existing_titles = {row['title'] for row in cursor.fetchall()}
                
                # ä¹Ÿæ£€æŸ¥æ˜¨å¤©çš„æ•°æ®åº“
                yesterday = (datetime.now(self.timezone) - timedelta(days=1)).strftime('%Y-%m-%d')
                yesterday_db = self._get_db_path(yesterday)
                if yesterday_db.exists():
                    with sqlite3.connect(yesterday_db) as yesterday_conn:
                        yesterday_conn.row_factory = sqlite3.Row
                        yesterday_cursor = yesterday_conn.cursor()
                        yesterday_cursor.execute('SELECT DISTINCT title FROM news')
                        existing_titles.update({row['title'] for row in yesterday_cursor.fetchall()})
                
                # è·å–æœ€æ–°ä¸€æ‰¹çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ? AND crawl_time = ?
                    ORDER BY platform_id, rank
                ''', (today, latest_time))
                latest_news = [dict(row) for row in cursor.fetchall()]
                
                # è¿‡æ»¤å‡ºæ–°å¢çš„æ–°é—»ï¼ˆæ ‡é¢˜ä¸åœ¨ä¹‹å‰çš„è®°å½•ä¸­ï¼‰
                incremental_news = [
                    news for news in latest_news 
                    if news['title'] not in existing_titles
                ]
                return incremental_news
            else:  # daily
                # è·å–å…¨å¤©çš„æ–°é—»
                cursor.execute('''
                    SELECT * FROM news 
                    WHERE date = ?
                    ORDER BY created_at DESC, platform_id, rank
                ''', (today,))
            
            rows = cursor.fetchall()
            return [dict(row) for row in rows]

    def _cleanup_old_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆåˆ é™¤æ—§çš„æ•°æ®åº“æ–‡ä»¶ï¼‰"""
        if self.retention_days <= 0:
            return
        
        cutoff_date = datetime.now(self.timezone) - timedelta(days=self.retention_days)
        
        # éå†æ•°æ®ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
        deleted_count = 0
        for db_file in self.data_dir.glob('news_*.db'):
            # æå–æ—¥æœŸ
            date_str = db_file.stem.replace('news_', '')  # 20260206
            try:
                file_date = datetime.strptime(date_str, '%Y%m%d')
                
                # å¦‚æœæ–‡ä»¶è¿‡æœŸï¼Œåˆ é™¤
                if file_date.date() < cutoff_date.date():
                    db_file.unlink()
                    deleted_count += 1
                    print(f"  âœ“ å·²åˆ é™¤è¿‡æœŸæ•°æ®åº“: {db_file.name}")
            except ValueError:
                # è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„æ–‡ä»¶
                continue
        
        if deleted_count > 0:
            print(f"âœ“ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¿‡æœŸæ•°æ®åº“æ–‡ä»¶")

    def get_database_stats(self) -> Dict:
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_news = 0
        platforms = set()
        db_files = list(self.data_dir.glob('news_*.db'))
        
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.now(self.timezone).strftime('%Y-%m-%d')
        today_news = 0
        
        # éå†æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
        for db_file in db_files:
            with sqlite3.connect(db_file) as conn:
                cursor = conn.cursor()
                
                # ç»Ÿè®¡æ–°é—»æ•°
                cursor.execute("SELECT COUNT(*) FROM news")
                count = cursor.fetchone()[0]
                total_news += count
                
                # ç»Ÿè®¡ä»Šæ—¥æ–°é—»æ•°
                cursor.execute("SELECT COUNT(*) FROM news WHERE date = ?", (today,))
                today_count = cursor.fetchone()[0]
                today_news += today_count
                
                # ç»Ÿè®¡å¹³å°æ•°
                cursor.execute("SELECT DISTINCT platform_id FROM news")
                platforms.update([row[0] for row in cursor.fetchall()])
        
        # è®¡ç®—æ€»å¤§å°
        total_size = sum(f.stat().st_size for f in db_files) / (1024 * 1024)  # MB
        
        return {
            'total_news': total_news,
            'today_news': today_news,
            'platform_count': len(platforms),
            'database_count': len(db_files),
            'db_size_mb': round(total_size, 2),
            'data_dir': str(self.data_dir),
        }
